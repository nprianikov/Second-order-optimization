{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_models.py --loop 0 --epochs 5 --batch_size 32 --dataset tmnist --optimizer HessianFree --model SmallCNN --wandb_mode 1 --wandb_log 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nohup python train_models --loop 0 --epochs 50 --batch_size 32 --dataset mnist --optimizer SGD --model SmallCNN --wandb_mode 0 --wandb_log 3 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_models.py --loop 0 --epochs 1 --batch_size 32 --dataset tmnist --optimizer HessianFree --model SmallCNN --wandb_mode 0 --wandb_log 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nprianikov/Second-order-optimization/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import src.engine as engine\n",
    "import src.experiments_maker as experiments_maker\n",
    "import wandb\n",
    "import time\n",
    "import utils.config_manager as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-------\n",
      "New experiment started at 2023_06_21_18_42_29\n",
      "\n",
      "Config: {'loop': 0, 'epochs': 1, 'lr': 0.003, 'batch_size': 128, 'dataset': 'cifar10', 'optimizer': 'K_BFGS(L)', 'model': 'SmallCNN', 'wandb_mode': 0, 'wandb_log': 3, 'wandb_log_freq': 0, 'wandb_log_batch': 1, 'slice_size': 1.0, 'activation_fn': 'Tanh', 'dropout': 0.0, 'checkpoints': 0}\n",
      "\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Im here!\n",
      "Im here!\n",
      "Im here!\n",
      "Im here!\n",
      "Im here!\n",
      "Batch: 0/391\n",
      "Loss: 2.2930500507354736\n",
      "Accuracy: 0.13262033462524414\n",
      "-------\n",
      "Batch: 0/391\n",
      "Loss: 2.3083581924438477\n",
      "Accuracy: 0.13603216409683228\n",
      "-------\n",
      "Batch: 1/391\n",
      "Loss: 2.298558235168457\n",
      "Accuracy: 0.1438596397638321\n",
      "-------\n",
      "Batch: 2/391\n",
      "Loss: 2.2944915294647217\n",
      "Accuracy: 0.10144230723381042\n",
      "-------\n",
      "Batch: 3/391\n",
      "Loss: 2.3024380207061768\n",
      "Accuracy: 0.1607142835855484\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [05:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m wandb\u001b[39m.\u001b[39minit(project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbaselines_cnn\u001b[39m\u001b[39m\"\u001b[39m, config\u001b[39m=\u001b[39mconfig, mode\u001b[39m=\u001b[39mcm\u001b[39m.\u001b[39mwandb_modes[\u001b[39m0\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     model, train_dataloader, test_dataloader, optimizer, criterion \u001b[39m=\u001b[39m experiments_maker\u001b[39m.\u001b[39mmake(config, cm\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m----> 4\u001b[0m     engine\u001b[39m.\u001b[39;49mtrain(model, train_dataloader, test_dataloader, cm\u001b[39m.\u001b[39;49mloss_fn, optimizer, criterion, cm\u001b[39m.\u001b[39;49mdevice, config)\n",
      "File \u001b[0;32m~/Second-order-optimization/src/../src/engine.py:216\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_data_loader, test_data_loader, loss_fn, optimizer, accuracy_fn, device, config)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39m# train loop\u001b[39;00m\n\u001b[1;32m    215\u001b[0m train_time_start \u001b[39m=\u001b[39m timer()\n\u001b[0;32m--> 216\u001b[0m train_loss, train_acc \u001b[39m=\u001b[39m train_step(data_loader\u001b[39m=\u001b[39;49mtrain_data_loader,\n\u001b[1;32m    217\u001b[0m                                    model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    218\u001b[0m                                    loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m    219\u001b[0m                                    optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    220\u001b[0m                                    accuracy_fn\u001b[39m=\u001b[39;49maccuracy_fn,\n\u001b[1;32m    221\u001b[0m                                    device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    222\u001b[0m                                    epoch\u001b[39m=\u001b[39;49mepoch,\n\u001b[1;32m    223\u001b[0m                                    config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    224\u001b[0m                                    checkpoints \u001b[39m=\u001b[39;49m checkpoints)\n\u001b[1;32m    225\u001b[0m train_time_end \u001b[39m=\u001b[39m timer()\n\u001b[1;32m    226\u001b[0m total_train_time_model \u001b[39m=\u001b[39m train_time_end \u001b[39m-\u001b[39m train_time_start\n",
      "File \u001b[0;32m~/Second-order-optimization/src/../src/engine.py:105\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, data_loader, loss_fn, optimizer, accuracy_fn, device, epoch, config, checkpoints)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m# get search direction\u001b[39;00m\n\u001b[1;32m    104\u001b[0m model \u001b[39m=\u001b[39m data_[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 105\u001b[0m data_, params \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mstep(data_, params)\n\u001b[1;32m    106\u001b[0m p_torch \u001b[39m=\u001b[39m data_[\u001b[39m'\u001b[39m\u001b[39mp_torch\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m get_if_nan(p_torch):\n",
      "File \u001b[0;32m~/Second-order-optimization/.conda/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Second-order-optimization/src/../src/optimizers/k_bfgs.py:133\u001b[0m, in \u001b[0;36mK_BFGS.step\u001b[0;34m(self, data_, params)\u001b[0m\n\u001b[1;32m    131\u001b[0m     action_a \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mKron_BFGS_action_a\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     step_ \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 133\u001b[0m     delta_l, data_ \u001b[39m=\u001b[39m Kron_BFGS_update_per_layer(data_, params, l, action_h, action_a, step_)\n\u001b[1;32m    134\u001b[0m     delta\u001b[39m.\u001b[39mappend(delta_l)\n\u001b[1;32m    136\u001b[0m p \u001b[39m=\u001b[39m get_opposite(delta)\n",
      "File \u001b[0;32m~/Second-order-optimization/src/../src/optimizers/k_bfgs.py:218\u001b[0m, in \u001b[0;36mKron_BFGS_update_per_layer\u001b[0;34m(data_, params, l, action_h, action_a, step_)\u001b[0m\n\u001b[1;32m    215\u001b[0m     decay_ \u001b[39m=\u001b[39m beta_\n\u001b[1;32m    216\u001b[0m     weight_ \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m-\u001b[39mbeta_\n\u001b[0;32m--> 218\u001b[0m     A_l \u001b[39m=\u001b[39m decay_ \u001b[39m*\u001b[39m A_l \u001b[39m+\u001b[39m weight_ \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39;49mmm(homo_h_l\u001b[39m.\u001b[39;49mt(), homo_h_l)\u001b[39m.\u001b[39mdata \u001b[39m/\u001b[39m data_[\u001b[39m'\u001b[39m\u001b[39mh_N2\u001b[39m\u001b[39m'\u001b[39m][l]\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m]\n\u001b[1;32m    220\u001b[0m Kron_BFGS_matrices_l[\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m A_l\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m action_h \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mHessian-action-BFGS\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mHessian-action-LBFGS\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = cm.create_config(epochs=1, lr=3e-3, batch_size=128, dataset='cifar10', optimizer='K_BFGS(L)', model='SmallCNN', wandb_log_batch=1)\n",
    "with wandb.init(project=\"baselines_cnn\", config=config, mode=cm.wandb_modes[0]):\n",
    "    model, train_dataloader, test_dataloader, optimizer, criterion = experiments_maker.make(config, cm.device)\n",
    "    engine.train(model, train_dataloader, test_dataloader, cm.loss_fn, optimizer, criterion, cm.device, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cm.create_config(epochs=1, batch_size=128, optimizer='SGD', model='DepthCNN', wandb_log_batch=32)\n",
    "model, train_dataloader, test_dataloader, optimizer, criterion = experiments_maker.make(config, cm.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X, y) in train_dataloader:\n",
    "    break\n",
    "X.to(cm.device)\n",
    "y.to(cm.device)\n",
    "# Forward pass\n",
    "y_pred = model(X)\n",
    "# Calculate loss\n",
    "loss = cm.loss_fn(y_pred, y)\n",
    "# Optimizer zero grad\n",
    "optimizer.zero_grad()\n",
    "# Loss backward\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'conv', 'input_size': 9, 'output_size': 32, 'tau': 676},\n",
       " {'name': 'conv', 'input_size': 288, 'output_size': 32, 'tau': 529},\n",
       " {'name': 'conv', 'input_size': 288, 'output_size': 64, 'tau': 400},\n",
       " {'name': 'fc', 'input_size': 23104, 'output_size': 64, 'tau': 1.0},\n",
       " {'name': 'fc', 'input_size': 64, 'output_size': 10, 'tau': 1.0}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
